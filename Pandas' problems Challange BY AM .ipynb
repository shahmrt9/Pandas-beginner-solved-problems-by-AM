{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704c1385",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73008ff",
   "metadata": {},
   "source": [
    "SQL Schema\n",
    "Pandas Schema\n",
    "Table: World\n",
    "\n",
    "+-------------+---------+\n",
    "| Column Name | Type    |\n",
    "+-------------+---------+\n",
    "| name        | varchar |\n",
    "| continent   | varchar |\n",
    "| area        | int     |\n",
    "| population  | int     |\n",
    "| gdp         | bigint  |\n",
    "+-------------+---------+\n",
    "name is the primary key (column with unique values) for this table.\n",
    "Each row of this table gives information about the name of a country, the continent to which it belongs, its area, the population, and its GDP value.\n",
    " \n",
    "\n",
    "A country is big if:\n",
    "\n",
    "it has an area of at least three million (i.e., 3000000 km2), or\n",
    "it has a population of at least twenty-five million (i.e., 25000000).\n",
    "Write a solution to find the name, population, and area of the big countries.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "World table:\n",
    "+-------------+-----------+---------+------------+--------------+\n",
    "| name        | continent | area    | population | gdp          |\n",
    "+-------------+-----------+---------+------------+--------------+\n",
    "| Afghanistan | Asia      | 652230  | 25500100   | 20343000000  |\n",
    "| Albania     | Europe    | 28748   | 2831741    | 12960000000  |\n",
    "| Algeria     | Africa    | 2381741 | 37100000   | 188681000000 |\n",
    "| Andorra     | Europe    | 468     | 78115      | 3712000000   |\n",
    "| Angola      | Africa    | 1246700 | 20609294   | 100990000000 |\n",
    "+-------------+-----------+---------+------------+--------------+\n",
    "Output: \n",
    "+-------------+------------+---------+\n",
    "| name        | population | area    |\n",
    "+-------------+------------+---------+\n",
    "| Afghanistan | 25500100   | 652230  |\n",
    "| Algeria     | 37100000   | 2381741 |\n",
    "+-------------+------------+---------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9751741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting word.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile word.csv\n",
    "\n",
    "| name        | continent | area    | population | gdp          |\n",
    "\n",
    "| Afghanistan | Asia      | 652230  | 25500100   | 20343000000  |\n",
    "| Albania     | Europe    | 28748   | 2831741    | 12960000000  |\n",
    "| Algeria     | Africa    | 2381741 | 37100000   | 188681000000 |\n",
    "| Andorra     | Europe    | 468     | 78115      | 3712000000   |\n",
    "| Angola      | Africa    | 1246700 | 20609294   | 100990000000 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb42ad6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>continent</th>\n",
       "      <th>area</th>\n",
       "      <th>population</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>652230</td>\n",
       "      <td>25500100</td>\n",
       "      <td>20343000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Europe</td>\n",
       "      <td>28748</td>\n",
       "      <td>2831741</td>\n",
       "      <td>12960000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Africa</td>\n",
       "      <td>2381741</td>\n",
       "      <td>37100000</td>\n",
       "      <td>188681000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>Europe</td>\n",
       "      <td>468</td>\n",
       "      <td>78115</td>\n",
       "      <td>3712000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Africa</td>\n",
       "      <td>1246700</td>\n",
       "      <td>20609294</td>\n",
       "      <td>100990000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name continent     area  population           gdp\n",
       "0  Afghanistan      Asia   652230    25500100   20343000000\n",
       "1      Albania    Europe    28748     2831741   12960000000\n",
       "2      Algeria    Africa  2381741    37100000  188681000000\n",
       "3      Andorra    Europe      468       78115    3712000000\n",
       "4       Angola    Africa  1246700    20609294  100990000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "world = pd.read_table('word.csv', sep=r' *\\| *', engine='python')\n",
    "\n",
    "world.drop(columns=['Unnamed: 0','Unnamed: 6'], axis=1, inplace=True)\n",
    "world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7acb6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def big_countries(world: pd.DataFrame) -> pd.DataFrame:\n",
    "    op = pd.DataFrame(columns=['name', 'population', 'area'])\n",
    "    for index, row in world.iterrows():\n",
    "        if row['area'] >= 3000000 or row['population'] >= 25000000:\n",
    "            op = op.append({'name': row['name'], 'population': row['population'], 'area': row['area']},ignore_index=True)\n",
    "    return op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf16c897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaha\\AppData\\Local\\Temp\\ipykernel_25544\\3103732240.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  op = op.append({'name': row['name'], 'population': row['population'], 'area': row['area']},ignore_index=True)\n",
      "C:\\Users\\shaha\\AppData\\Local\\Temp\\ipykernel_25544\\3103732240.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  op = op.append({'name': row['name'], 'population': row['population'], 'area': row['area']},ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>population</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>25500100</td>\n",
       "      <td>652230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>37100000</td>\n",
       "      <td>2381741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name population     area\n",
       "0  Afghanistan   25500100   652230\n",
       "1      Algeria   37100000  2381741"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_countries(world)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d2995",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba10361",
   "metadata": {},
   "source": [
    "Write a solution to find the ids of products that are both low fat and recyclable.\n",
    "\n",
    "Return the result table in any order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a773f720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Products.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile Products.csv\n",
    "\n",
    "\n",
    "| product_id  | low_fats | recyclable |\n",
    "\n",
    "| 0           | Y        | N          |\n",
    "| 1           | Y        | Y          |\n",
    "| 2           | N        | Y          |\n",
    "| 3           | Y        | Y          |\n",
    "| 4           | N        | N          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6228820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>low_fats</th>\n",
       "      <th>recyclable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id low_fats recyclable\n",
       "0           0        Y          N\n",
       "1           1        Y          Y\n",
       "2           2        N          Y\n",
       "3           3        Y          Y\n",
       "4           4        N          N"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Products=pd.read_table('Products.csv',sep=r' *\\| *', engine='python')\n",
    "Products.drop(columns=['Unnamed: 0','Unnamed: 4'],axis=1, inplace=True)\n",
    "Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba4cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_products(Products: pd.DataFrame) -> pd.DataFrame:\n",
    "    op=[]\n",
    "    for index, row in Products.iterrows():\n",
    "        \n",
    "        if row['low_fats'] == 'Y' and row['recyclable'] == 'Y':\n",
    "            op.append({'product_id': row['product_id']})\n",
    "    return pd.DataFrame(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38ef2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id\n",
       "0           1\n",
       "1           3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_products(Products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a32fd0",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44717f51",
   "metadata": {},
   "source": [
    "Write a solution to find all customers who never order anything.\n",
    "\n",
    "Return the result table in any order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e690b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting customers.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile customers.csv\n",
    "\n",
    "| id | name  |\n",
    "\n",
    "| 1  | Joe   |\n",
    "| 2  | Henry |\n",
    "| 3  | Sam   |\n",
    "| 4  | Max   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13a1457d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Joe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Sam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Max</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name\n",
       "0   1    Joe\n",
       "1   2  Henry\n",
       "2   3    Sam\n",
       "3   4    Max"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers=pd.read_table('customers.csv',sep=r' *\\| *', engine='python')\n",
    "customers.drop(columns=['Unnamed: 0','Unnamed: 3'],axis=1, inplace=True)\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddbc5b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting orders.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile orders.csv\n",
    "\n",
    "| id | customerId |\n",
    "\n",
    "| 1  | 3          |\n",
    "| 2  | 1          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad296649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>customerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  customerId\n",
       "0   1           3\n",
       "1   2           1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders=pd.read_table('orders.csv',sep=r' *\\| *', engine='python')\n",
    "orders.drop(columns=['Unnamed: 0','Unnamed: 3'],axis=1, inplace=True)\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b246737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>id_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Joe</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Henry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Sam</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Max</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name  id_order\n",
       "0   1    Joe       2.0\n",
       "1   2  Henry       NaN\n",
       "2   3    Sam       1.0\n",
       "3   4    Max       NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_order = customers.join(orders.set_index('customerId'), on='id', how='outer', rsuffix='_order')\n",
    "cust_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57684bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_customers(customers: pd.DataFrame, orders: pd.DataFrame) -> pd.DataFrame:\n",
    "    cust_order = customers.join(orders.set_index('customerId'), on='id', how='outer', rsuffix='_order')\n",
    "    selected_customers = cust_order[cust_order['id_order'].isnull()]\n",
    "\n",
    "    return selected_customers[['name']].rename(columns={'name': 'Customers'})  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2bd165a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Max</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customers\n",
       "1     Henry\n",
       "3       Max"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_customers(customers,orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3ab59",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea5fe87",
   "metadata": {},
   "source": [
    "+---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| article_id    | int     |\n",
    "| author_id     | int     |\n",
    "| viewer_id     | int     |\n",
    "| view_date     | date    |\n",
    "+---------------+---------+\n",
    "There is no primary key (column with unique values) for this table, the table may have duplicate rows.\n",
    "Each row of this table indicates that some viewer viewed an article (written by some author) on some date. \n",
    "Note that equal author_id and viewer_id indicate the same person.\n",
    " \n",
    "\n",
    "Write a solution to find all the authors that viewed at least one of their own articles.\n",
    "\n",
    "Return the result table sorted by id in ascending order.\n",
    "\n",
    "The result format is in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d7e58dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting views.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile views.csv\n",
    "\n",
    "| article_id | author_id | viewer_id | view_date  |\n",
    "\n",
    "| 126        | 17        | 62        | 2019-07-02 |\n",
    "| 149        | 42        | 22        | 2019-06-23 |\n",
    "| 138        | 39        | 33        | 2019-07-26 |\n",
    "| 165        | 42        | 74        | 2019-07-05 |\n",
    "| 48         | 95        | 91        | 2019-06-28 |\n",
    "| 151        | 30        | 19        | 2019-06-22 |\n",
    "| 195        | 76        | 65        | 2019-07-24 |\n",
    "| 67         | 4         | 91        | 2019-06-01 |\n",
    "| 91         | 55        | 13        | 2019-07-11 |\n",
    "| 126        | 17        | 77        | 2019-06-14 |\n",
    "| 142        | 38        | 100       | 2019-07-07 |\n",
    "| 148        | 63        | 48        | 2019-07-21 |\n",
    "| 156        | 24        | 8         | 2019-07-29 |\n",
    "| 63         | 73        | 30        | 2019-06-16 |\n",
    "| 32         | 93        | 66        | 2019-07-23 |\n",
    "| 143        | 10        | 38        | 2019-07-31 |\n",
    "| 171        | 82        | 2         | 2019-07-25 |\n",
    "| 88         | 61        | 67        | 2019-07-02 |\n",
    "| 40         | 92        | 67        | 2019-06-03 |\n",
    "| 23         | 18        | 39        | 2019-07-20 |\n",
    "| 51         | 41        | 10        | 2019-07-17 |\n",
    "| 76         | 10        | 65        | 2019-07-13 |\n",
    "| 123        | 50        | 23        | 2019-07-06 |\n",
    "| 77         | 76        | 1         | 2019-07-02 |\n",
    "| 176        | 25        | 39        | 2019-06-01 |\n",
    "| 4          | 34        | 100       | 2019-06-26 |\n",
    "| 175        | 82        | 48        | 2019-06-04 |\n",
    "| 109        | 47        | 65        | 2019-07-19 |\n",
    "| 168        | 67        | 46        | 2019-07-12 |\n",
    "| 129        | 49        | 74        | 2019-06-09 |\n",
    "| 162        | 60        | 89        | 2019-06-18 |\n",
    "| 40         | 92        | 24        | 2019-07-21 |\n",
    "| 108        | 19        | 17        | 2019-07-27 |\n",
    "| 68         | 83        | 19        | 2019-06-21 |\n",
    "| 22         | 62        | 26        | 2019-07-29 |\n",
    "| 190        | 9         | 13        | 2019-06-22 |\n",
    "| 50         | 57        | 95        | 2019-06-21 |\n",
    "| 47         | 49        | 29        | 2019-06-05 |\n",
    "| 155        | 29        | 87        | 2019-06-25 |\n",
    "| 158        | 25        | 57        | 2019-07-14 |\n",
    "| 101        | 24        | 7         | 2019-07-24 |\n",
    "| 189        | 43        | 40        | 2019-07-21 |\n",
    "| 148        | 63        | 49        | 2019-06-18 |\n",
    "| 150        | 75        | 73        | 2019-06-27 |\n",
    "| 11         | 53        | 56        | 2019-07-11 |\n",
    "| 131        | 65        | 70        | 2019-06-10 |\n",
    "| 124        | 21        | 25        | 2019-07-12 |\n",
    "| 80         | 8         | 33        | 2019-06-05 |\n",
    "| 129        | 49        | 81        | 2019-08-01 |\n",
    "| 172        | 2         | 33        | 2019-06-23 |\n",
    "| 21         | 3         | 63        | 2019-07-31 |\n",
    "| 104        | 97        | 92        | 2019-07-25 |\n",
    "| 46         | 81        | 8         | 2019-06-13 |\n",
    "| 169        | 30        | 50        | 2019-06-12 |\n",
    "| 70         | 93        | 59        | 2019-06-01 |\n",
    "| 7          | 15        | 73        | 2019-06-25 |\n",
    "| 146        | 53        | 9         | 2019-07-07 |\n",
    "| 114        | 83        | 67        | 2019-06-16 |\n",
    "| 32         | 93        | 78        | 2019-07-20 |\n",
    "| 18         | 7         | 47        | 2019-07-17 |\n",
    "| 78         | 87        | 92        | 2019-07-13 |\n",
    "| 39         | 93        | 62        | 2019-07-14 |\n",
    "| 180        | 43        | 8         | 2019-06-27 |\n",
    "| 105        | 81        | 45        | 2019-07-10 |\n",
    "| 184        | 7         | 56        | 2019-07-16 |\n",
    "| 58         | 93        | 58        | 2019-07-27 |\n",
    "| 176        | 25        | 40        | 2019-07-23 |\n",
    "| 48         | 95        | 71        | 2019-07-17 |\n",
    "| 186        | 28        | 70        | 2019-06-14 |\n",
    "| 85         | 74        | 46        | 2019-07-03 |\n",
    "| 132        | 4         | 49        | 2019-06-24 |\n",
    "| 103        | 11        | 84        | 2019-06-15 |\n",
    "| 56         | 11        | 63        | 2019-06-07 |\n",
    "| 111        | 71        | 51        | 2019-07-07 |\n",
    "| 2          | 47        | 27        | 2019-07-22 |\n",
    "| 133        | 40        | 85        | 2019-06-02 |\n",
    "| 23         | 18        | 3         | 2019-07-07 |\n",
    "| 130        | 2         | 19        | 2019-07-06 |\n",
    "| 142        | 38        | 90        | 2019-07-06 |\n",
    "| 133        | 40        | 1         | 2019-07-20 |\n",
    "| 131        | 65        | 64        | 2019-07-26 |\n",
    "| 15         | 37        | 21        | 2019-07-27 |\n",
    "| 111        | 71        | 68        | 2019-06-16 |\n",
    "| 84         | 48        | 70        | 2019-07-08 |\n",
    "| 133        | 40        | 14        | 2019-06-13 |\n",
    "| 31         | 85        | 80        | 2019-06-01 |\n",
    "| 183        | 13        | 87        | 2019-07-16 |\n",
    "| 114        | 83        | 58        | 2019-06-08 |\n",
    "| 40         | 92        | 87        | 2019-07-08 |\n",
    "| 122        | 36        | 94        | 2019-07-02 |\n",
    "| 135        | 96        | 47        | 2019-07-26 |\n",
    "| 96         | 92        | 73        | 2019-06-22 |\n",
    "| 97         | 23        | 14        | 2019-06-11 |\n",
    "| 83         | 74        | 85        | 2019-07-20 |\n",
    "| 143        | 10        | 2         | 2019-06-08 |\n",
    "| 193        | 85        | 91        | 2019-06-22 |\n",
    "| 56         | 11        | 55        | 2019-06-25 |\n",
    "| 20         | 19        | 75        | 2019-07-19 |\n",
    "| 70         | 93        | 36        | 2019-07-01 |\n",
    "| 168        | 67        | 22        | 2019-06-06 |\n",
    "| 71         | 27        | 45        | 2019-06-14 |\n",
    "| 176        | 25        | 92        | 2019-06-05 |\n",
    "| 198        | 40        | 96        | 2019-07-08 |\n",
    "| 168        | 67        | 51        | 2019-07-28 |\n",
    "| 78         | 87        | 5         | 2019-07-18 |\n",
    "| 154        | 3         | 12        | 2019-06-19 |\n",
    "| 168        | 67        | 18        | 2019-06-26 |\n",
    "| 67         | 4         | 37        | 2019-06-10 |\n",
    "| 173        | 73        | 18        | 2019-06-22 |\n",
    "| 162        | 60        | 83        | 2019-07-24 |\n",
    "| 37         | 83        | 36        | 2019-07-26 |\n",
    "| 127        | 19        | 88        | 2019-07-26 |\n",
    "| 199        | 71        | 67        | 2019-07-06 |\n",
    "| 12         | 34        | 2         | 2019-06-22 |\n",
    "| 45         | 16        | 63        | 2019-06-19 |\n",
    "| 139        | 29        | 37        | 2019-07-30 |\n",
    "| 179        | 64        | 65        | 2019-07-02 |\n",
    "| 9          | 55        | 2         | 2019-06-20 |\n",
    "| 16         | 94        | 81        | 2019-07-08 |\n",
    "| 66         | 32        | 35        | 2019-07-19 |\n",
    "| 168        | 67        | 90        | 2019-07-08 |\n",
    "| 147        | 99        | 60        | 2019-06-17 |\n",
    "| 42         | 7         | 63        | 2019-07-18 |\n",
    "| 18         | 7         | 79        | 2019-07-06 |\n",
    "| 113        | 61        | 3         | 2019-07-24 |\n",
    "| 129        | 49        | 80        | 2019-06-07 |\n",
    "| 51         | 41        | 44        | 2019-07-18 |\n",
    "| 102        | 48        | 96        | 2019-07-24 |\n",
    "| 122        | 36        | 80        | 2019-07-16 |\n",
    "| 193        | 85        | 87        | 2019-07-24 |\n",
    "| 16         | 94        | 32        | 2019-07-01 |\n",
    "| 20         | 19        | 45        | 2019-07-09 |\n",
    "| 172        | 2         | 84        | 2019-06-15 |\n",
    "| 87         | 60        | 60        | 2019-07-16 |\n",
    "| 24         | 43        | 69        | 2019-07-30 |\n",
    "| 57         | 57        | 11        | 2019-06-29 |\n",
    "| 72         | 43        | 5         | 2019-06-06 |\n",
    "| 173        | 73        | 45        | 2019-07-31 |\n",
    "| 156        | 24        | 22        | 2019-06-21 |\n",
    "| 130        | 2         | 43        | 2019-06-24 |\n",
    "| 111        | 71        | 71        | 2019-06-23 |\n",
    "| 12         | 34        | 13        | 2019-06-22 |\n",
    "| 115        | 89        | 78        | 2019-06-28 |\n",
    "| 12         | 34        | 31        | 2019-06-06 |\n",
    "| 1          | 67        | 74        | 2019-07-23 |\n",
    "| 93         | 98        | 41        | 2019-07-17 |\n",
    "| 94         | 50        | 65        | 2019-07-03 |\n",
    "| 50         | 57        | 25        | 2019-07-09 |\n",
    "| 165        | 42        | 79        | 2019-07-01 |\n",
    "| 37         | 83        | 51        | 2019-07-28 |\n",
    "| 148        | 63        | 77        | 2019-07-09 |\n",
    "| 119        | 72        | 5         | 2019-07-22 |\n",
    "| 97         | 23        | 24        | 2019-06-13 |\n",
    "| 133        | 40        | 95        | 2019-07-07 |\n",
    "| 37         | 83        | 60        | 2019-07-13 |\n",
    "| 110        | 48        | 97        | 2019-07-28 |\n",
    "| 23         | 18        | 66        | 2019-06-22 |\n",
    "| 183        | 13        | 25        | 2019-07-27 |\n",
    "| 47         | 49        | 10        | 2019-06-03 |\n",
    "| 83         | 74        | 57        | 2019-06-07 |\n",
    "| 58         | 93        | 66        | 2019-06-30 |\n",
    "| 193        | 85        | 93        | 2019-06-09 |\n",
    "| 144        | 66        | 7         | 2019-06-07 |\n",
    "| 192        | 10        | 100       | 2019-06-23 |\n",
    "| 158        | 25        | 48        | 2019-07-04 |\n",
    "| 125        | 76        | 72        | 2019-06-21 |\n",
    "| 4          | 34        | 7         | 2019-07-02 |\n",
    "| 19         | 78        | 5         | 2019-07-18 |\n",
    "| 164        | 51        | 69        | 2019-07-04 |\n",
    "| 9          | 55        | 35        | 2019-07-26 |\n",
    "| 127        | 19        | 34        | 2019-06-04 |\n",
    "| 133        | 40        | 65        | 2019-07-07 |\n",
    "| 107        | 90        | 30        | 2019-06-28 |\n",
    "| 173        | 73        | 96        | 2019-06-10 |\n",
    "| 118        | 43        | 20        | 2019-06-27 |\n",
    "| 141        | 15        | 69        | 2019-06-30 |\n",
    "| 75         | 100       | 35        | 2019-08-01 |\n",
    "| 141        | 15        | 35        | 2019-06-01 |\n",
    "| 183        | 13        | 27        | 2019-06-21 |\n",
    "| 131        | 65        | 33        | 2019-06-07 |\n",
    "| 75         | 100       | 89        | 2019-06-02 |\n",
    "| 104        | 97        | 61        | 2019-07-21 |\n",
    "| 126        | 17        | 33        | 2019-06-22 |\n",
    "| 50         | 57        | 75        | 2019-06-17 |\n",
    "| 48         | 95        | 27        | 2019-06-05 |\n",
    "| 147        | 99        | 13        | 2019-07-07 |\n",
    "| 50         | 57        | 72        | 2019-06-30 |\n",
    "| 102        | 48        | 2         | 2019-07-01 |\n",
    "| 2          | 47        | 36        | 2019-06-22 |\n",
    "| 76         | 10        | 2         | 2019-07-03 |\n",
    "| 88         | 61        | 57        | 2019-07-12 |\n",
    "| 94         | 50        | 15        | 2019-07-01 |\n",
    "| 150        | 75        | 6         | 2019-07-01 |\n",
    "| 173        | 73        | 92        | 2019-06-10 |\n",
    "| 165        | 42        | 76        | 2019-07-20 |\n",
    "| 101        | 24        | 59        | 2019-06-15 |\n",
    "| 83         | 74        | 64        | 2019-07-30 |\n",
    "| 160        | 7         | 51        | 2019-07-10 |\n",
    "| 88         | 61        | 48        | 2019-07-11 |\n",
    "| 23         | 18        | 16        | 2019-07-09 |\n",
    "| 153        | 94        | 97        | 2019-07-27 |\n",
    "| 161        | 26        | 6         | 2019-07-07 |\n",
    "| 29         | 8         | 73        | 2019-06-02 |\n",
    "| 13         | 93        | 78        | 2019-06-15 |\n",
    "| 118        | 43        | 82        | 2019-06-01 |\n",
    "| 123        | 50        | 9         | 2019-07-11 |\n",
    "| 155        | 29        | 56        | 2019-07-10 |\n",
    "| 45         | 16        | 67        | 2019-06-22 |\n",
    "| 65         | 69        | 21        | 2019-07-01 |\n",
    "| 185        | 30        | 98        | 2019-06-22 |\n",
    "| 64         | 77        | 56        | 2019-06-21 |\n",
    "| 147        | 99        | 31        | 2019-07-03 |\n",
    "| 4          | 34        | 80        | 2019-07-20 |\n",
    "| 86         | 47        | 61        | 2019-06-15 |\n",
    "| 93         | 98        | 24        | 2019-07-22 |\n",
    "| 80         | 8         | 81        | 2019-07-14 |\n",
    "| 99         | 17        | 4         | 2019-07-09 |\n",
    "| 140        | 18        | 37        | 2019-06-28 |\n",
    "| 4          | 34        | 61        | 2019-06-12 |\n",
    "| 107        | 90        | 22        | 2019-08-01 |\n",
    "| 73         | 84        | 4         | 2019-07-23 |\n",
    "| 126        | 17        | 17        | 2019-07-27 |\n",
    "| 35         | 50        | 100       | 2019-06-29 |\n",
    "| 101        | 24        | 88        | 2019-06-07 |\n",
    "| 191        | 5         | 43        | 2019-07-21 |\n",
    "| 63         | 73        | 63        | 2019-07-21 |\n",
    "| 91         | 55        | 84        | 2019-07-27 |\n",
    "| 185        | 30        | 80        | 2019-06-29 |\n",
    "| 137        | 90        | 82        | 2019-07-30 |\n",
    "| 113        | 61        | 14        | 2019-07-24 |\n",
    "| 166        | 85        | 58        | 2019-06-04 |\n",
    "| 132        | 4         | 99        | 2019-06-07 |\n",
    "| 151        | 30        | 90        | 2019-07-04 |\n",
    "| 72         | 43        | 46        | 2019-07-13 |\n",
    "| 97         | 23        | 29        | 2019-08-01 |\n",
    "| 182        | 28        | 65        | 2019-07-07 |\n",
    "| 89         | 62        | 61        | 2019-07-15 |\n",
    "| 130        | 2         | 48        | 2019-06-13 |\n",
    "| 171        | 82        | 5         | 2019-06-12 |\n",
    "| 32         | 93        | 64        | 2019-06-02 |\n",
    "| 80         | 8         | 5         | 2019-06-28 |\n",
    "| 48         | 95        | 91        | 2019-06-18 |\n",
    "| 128        | 6         | 83        | 2019-07-31 |\n",
    "| 55         | 27        | 3         | 2019-06-18 |\n",
    "| 162        | 60        | 68        | 2019-06-27 |\n",
    "| 183        | 13        | 95        | 2019-06-29 |\n",
    "| 132        | 4         | 65        | 2019-06-25 |\n",
    "| 194        | 19        | 72        | 2019-07-14 |\n",
    "| 172        | 2         | 28        | 2019-07-09 |\n",
    "| 137        | 90        | 63        | 2019-07-11 |\n",
    "| 102        | 48        | 68        | 2019-07-22 |\n",
    "| 159        | 1         | 58        | 2019-06-07 |\n",
    "| 35         | 50        | 27        | 2019-07-25 |\n",
    "| 167        | 84        | 78        | 2019-06-04 |\n",
    "| 71         | 27        | 34        | 2019-07-12 |\n",
    "| 69         | 52        | 92        | 2019-07-14 |\n",
    "| 21         | 3         | 79        | 2019-07-03 |\n",
    "| 124        | 21        | 97        | 2019-06-02 |\n",
    "| 122        | 36        | 8         | 2019-07-29 |\n",
    "| 18         | 7         | 57        | 2019-06-15 |\n",
    "| 131        | 65        | 60        | 2019-06-06 |\n",
    "| 153        | 94        | 66        | 2019-06-03 |\n",
    "| 138        | 39        | 55        | 2019-07-26 |\n",
    "| 194        | 19        | 43        | 2019-07-29 |\n",
    "| 190        | 9         | 96        | 2019-07-26 |\n",
    "| 117        | 74        | 17        | 2019-06-28 |\n",
    "| 177        | 22        | 84        | 2019-06-15 |\n",
    "| 20         | 19        | 32        | 2019-07-28 |\n",
    "| 103        | 11        | 48        | 2019-06-28 |\n",
    "| 62         | 14        | 40        | 2019-06-30 |\n",
    "| 8          | 39        | 6         | 2019-06-29 |\n",
    "| 183        | 13        | 49        | 2019-07-25 |\n",
    "| 191        | 5         | 29        | 2019-07-19 |\n",
    "| 46         | 81        | 35        | 2019-06-04 |\n",
    "| 76         | 10        | 82        | 2019-06-07 |\n",
    "| 168        | 67        | 88        | 2019-07-13 |\n",
    "| 171        | 82        | 60        | 2019-06-30 |\n",
    "| 14         | 17        | 52        | 2019-07-30 |\n",
    "| 97         | 23        | 69        | 2019-07-15 |\n",
    "| 45         | 16        | 76        | 2019-06-29 |\n",
    "| 156        | 24        | 65        | 2019-06-17 |\n",
    "| 16         | 94        | 96        | 2019-07-24 |\n",
    "| 155        | 29        | 20        | 2019-07-16 |\n",
    "| 158        | 25        | 6         | 2019-07-19 |\n",
    "| 125        | 76        | 24        | 2019-07-03 |\n",
    "| 83         | 74        | 8         | 2019-07-21 |\n",
    "| 85         | 74        | 3         | 2019-07-17 |\n",
    "| 147        | 99        | 81        | 2019-07-18 |\n",
    "| 133        | 40        | 40        | 2019-08-01 |\n",
    "| 16         | 94        | 37        | 2019-07-02 |\n",
    "| 118        | 43        | 32        | 2019-07-11 |\n",
    "| 114        | 83        | 39        | 2019-06-04 |\n",
    "| 36         | 43        | 95        | 2019-06-18 |\n",
    "| 140        | 18        | 24        | 2019-07-04 |\n",
    "| 29         | 8         | 10        | 2019-07-14 |\n",
    "| 182        | 28        | 23        | 2019-07-02 |\n",
    "| 81         | 1         | 85        | 2019-07-02 |\n",
    "| 79         | 28        | 62        | 2019-06-10 |\n",
    "| 116        | 53        | 70        | 2019-07-10 |\n",
    "| 182        | 28        | 97        | 2019-06-04 |\n",
    "| 59         | 24        | 36        | 2019-06-13 |\n",
    "| 17         | 51        | 38        | 2019-06-20 |\n",
    "| 10         | 78        | 88        | 2019-06-06 |\n",
    "| 66         | 32        | 83        | 2019-06-16 |\n",
    "| 200        | 92        | 87        | 2019-06-04 |\n",
    "| 156        | 24        | 47        | 2019-06-10 |\n",
    "| 119        | 72        | 4         | 2019-07-27 |\n",
    "| 104        | 97        | 6         | 2019-06-02 |\n",
    "| 104        | 97        | 9         | 2019-07-04 |\n",
    "| 158        | 25        | 2         | 2019-07-08 |\n",
    "| 161        | 26        | 70        | 2019-07-12 |\n",
    "| 80         | 8         | 82        | 2019-06-14 |\n",
    "| 32         | 93        | 24        | 2019-06-16 |\n",
    "| 4          | 34        | 93        | 2019-06-17 |\n",
    "| 154        | 3         | 13        | 2019-07-15 |\n",
    "| 200        | 92        | 71        | 2019-06-23 |\n",
    "| 179        | 64        | 61        | 2019-06-11 |\n",
    "| 180        | 43        | 77        | 2019-07-02 |\n",
    "| 87         | 60        | 86        | 2019-07-19 |\n",
    "| 169        | 30        | 76        | 2019-07-19 |\n",
    "| 37         | 83        | 86        | 2019-06-10 |\n",
    "| 128        | 6         | 1         | 2019-07-22 |\n",
    "| 7          | 15        | 84        | 2019-06-25 |\n",
    "| 106        | 48        | 71        | 2019-06-06 |\n",
    "| 50         | 57        | 62        | 2019-07-01 |\n",
    "| 187        | 53        | 42        | 2019-06-10 |\n",
    "| 59         | 24        | 19        | 2019-06-08 |\n",
    "| 156        | 24        | 20        | 2019-07-22 |\n",
    "| 3          | 68        | 62        | 2019-06-09 |\n",
    "| 188        | 85        | 20        | 2019-06-29 |\n",
    "| 39         | 93        | 30        | 2019-06-22 |\n",
    "| 9          | 55        | 100       | 2019-06-29 |\n",
    "| 62         | 14        | 81        | 2019-07-05 |\n",
    "| 80         | 8         | 32        | 2019-06-14 |\n",
    "| 149        | 42        | 87        | 2019-07-04 |\n",
    "| 192        | 10        | 15        | 2019-06-12 |\n",
    "| 120        | 59        | 1         | 2019-06-13 |\n",
    "| 158        | 25        | 75        | 2019-06-13 |\n",
    "| 51         | 41        | 68        | 2019-06-27 |\n",
    "| 175        | 82        | 17        | 2019-06-17 |\n",
    "| 132        | 4         | 89        | 2019-06-06 |\n",
    "| 121        | 5         | 5         | 2019-06-26 |\n",
    "| 67         | 4         | 14        | 2019-06-02 |\n",
    "| 57         | 57        | 93        | 2019-07-09 |\n",
    "| 58         | 93        | 57        | 2019-06-22 |\n",
    "| 57         | 57        | 13        | 2019-07-26 |\n",
    "| 126        | 17        | 18        | 2019-07-22 |\n",
    "| 111        | 71        | 86        | 2019-06-11 |\n",
    "| 197        | 5         | 5         | 2019-07-25 |\n",
    "| 147        | 99        | 61        | 2019-07-09 |\n",
    "| 40         | 92        | 77        | 2019-06-14 |\n",
    "| 44         | 91        | 71        | 2019-06-07 |\n",
    "| 13         | 93        | 78        | 2019-06-23 |\n",
    "| 76         | 10        | 52        | 2019-07-23 |\n",
    "| 78         | 87        | 70        | 2019-07-22 |\n",
    "| 87         | 60        | 56        | 2019-06-29 |\n",
    "| 15         | 37        | 85        | 2019-08-01 |\n",
    "| 143        | 10        | 81        | 2019-07-02 |\n",
    "| 186        | 28        | 37        | 2019-06-30 |\n",
    "| 84         | 48        | 16        | 2019-07-07 |\n",
    "| 23         | 18        | 31        | 2019-07-28 |\n",
    "| 51         | 41        | 46        | 2019-06-29 |\n",
    "| 174        | 70        | 41        | 2019-06-02 |\n",
    "| 139        | 29        | 85        | 2019-07-18 |\n",
    "| 57         | 57        | 20        | 2019-07-14 |\n",
    "| 184        | 7         | 36        | 2019-07-19 |\n",
    "| 21         | 3         | 73        | 2019-06-16 |\n",
    "| 21         | 3         | 48        | 2019-07-23 |\n",
    "| 114        | 83        | 38        | 2019-07-07 |\n",
    "| 128        | 6         | 11        | 2019-06-15 |\n",
    "| 5          | 22        | 45        | 2019-07-31 |\n",
    "| 144        | 66        | 50        | 2019-06-26 |\n",
    "| 135        | 96        | 85        | 2019-06-28 |\n",
    "| 196        | 74        | 90        | 2019-06-08 |\n",
    "| 15         | 37        | 8         | 2019-07-12 |\n",
    "| 86         | 47        | 79        | 2019-07-11 |\n",
    "| 42         | 7         | 75        | 2019-06-15 |\n",
    "| 200        | 92        | 62        | 2019-07-12 |\n",
    "| 3          | 68        | 74        | 2019-06-21 |\n",
    "| 12         | 34        | 26        | 2019-06-28 |\n",
    "| 40         | 92        | 28        | 2019-07-12 |\n",
    "| 120        | 59        | 28        | 2019-06-19 |\n",
    "| 3          | 68        | 69        | 2019-06-20 |\n",
    "| 56         | 11        | 19        | 2019-07-24 |\n",
    "| 25         | 47        | 10        | 2019-06-03 |\n",
    "| 156        | 24        | 79        | 2019-07-31 |\n",
    "| 159        | 1         | 12        | 2019-07-19 |\n",
    "| 131        | 65        | 89        | 2019-06-03 |\n",
    "| 32         | 93        | 1         | 2019-06-16 |\n",
    "| 25         | 47        | 16        | 2019-06-22 |\n",
    "| 161        | 26        | 93        | 2019-06-09 |\n",
    "| 188        | 85        | 13        | 2019-07-18 |\n",
    "| 55         | 27        | 49        | 2019-06-18 |\n",
    "| 167        | 84        | 12        | 2019-07-07 |\n",
    "| 97         | 23        | 8         | 2019-07-28 |\n",
    "| 52         | 85        | 3         | 2019-07-15 |\n",
    "| 156        | 24        | 92        | 2019-07-25 |\n",
    "| 5          | 22        | 17        | 2019-07-25 |\n",
    "| 22         | 62        | 60        | 2019-07-14 |\n",
    "| 177        | 22        | 29        | 2019-06-14 |\n",
    "| 30         | 65        | 10        | 2019-06-28 |\n",
    "| 95         | 64        | 27        | 2019-07-18 |\n",
    "| 110        | 48        | 29        | 2019-06-21 |\n",
    "| 71         | 27        | 79        | 2019-07-02 |\n",
    "| 98         | 15        | 82        | 2019-06-08 |\n",
    "| 165        | 42        | 86        | 2019-06-27 |\n",
    "| 101        | 24        | 70        | 2019-06-12 |\n",
    "| 80         | 8         | 15        | 2019-07-12 |\n",
    "| 73         | 84        | 4         | 2019-07-23 |\n",
    "| 107        | 90        | 87        | 2019-06-08 |\n",
    "| 34         | 16        | 4         | 2019-07-06 |\n",
    "| 143        | 10        | 93        | 2019-07-12 |\n",
    "| 4          | 34        | 3         | 2019-07-25 |\n",
    "| 82         | 82        | 67        | 2019-08-01 |\n",
    "| 60         | 77        | 37        | 2019-07-01 |\n",
    "| 115        | 89        | 94        | 2019-07-22 |\n",
    "| 197        | 5         | 6         | 2019-06-18 |\n",
    "| 21         | 3         | 14        | 2019-07-05 |\n",
    "| 138        | 39        | 14        | 2019-06-16 |\n",
    "| 194        | 19        | 26        | 2019-07-15 |\n",
    "| 27         | 40        | 50        | 2019-06-18 |\n",
    "| 145        | 88        | 35        | 2019-06-18 |\n",
    "| 77         | 76        | 36        | 2019-07-29 |\n",
    "| 78         | 87        | 25        | 2019-06-16 |\n",
    "| 142        | 38        | 82        | 2019-06-04 |\n",
    "| 51         | 41        | 21        | 2019-07-14 |\n",
    "| 25         | 47        | 62        | 2019-07-13 |\n",
    "| 194        | 19        | 32        | 2019-07-19 |\n",
    "| 30         | 65        | 1         | 2019-07-29 |\n",
    "| 87         | 60        | 14        | 2019-07-05 |\n",
    "| 164        | 51        | 3         | 2019-07-23 |\n",
    "| 161        | 26        | 9         | 2019-07-01 |\n",
    "| 15         | 37        | 72        | 2019-07-01 |\n",
    "| 111        | 71        | 57        | 2019-07-09 |\n",
    "| 43         | 57        | 76        | 2019-07-23 |\n",
    "| 19         | 78        | 83        | 2019-07-25 |\n",
    "| 80         | 8         | 63        | 2019-07-21 |\n",
    "| 171        | 82        | 79        | 2019-06-22 |\n",
    "| 81         | 1         | 6         | 2019-06-06 |\n",
    "| 25         | 47        | 46        | 2019-07-19 |\n",
    "| 23         | 18        | 96        | 2019-07-20 |\n",
    "| 65         | 69        | 97        | 2019-07-03 |\n",
    "| 6          | 73        | 47        | 2019-06-24 |\n",
    "| 182        | 28        | 28        | 2019-06-03 |\n",
    "| 159        | 1         | 32        | 2019-07-12 |\n",
    "| 42         | 7         | 56        | 2019-07-17 |\n",
    "| 71         | 27        | 5         | 2019-07-20 |\n",
    "| 44         | 91        | 80        | 2019-07-06 |\n",
    "| 55         | 27        | 73        | 2019-07-10 |\n",
    "| 28         | 34        | 80        | 2019-07-27 |\n",
    "| 106        | 48        | 13        | 2019-07-08 |\n",
    "| 107        | 90        | 81        | 2019-06-24 |\n",
    "| 130        | 2         | 80        | 2019-07-15 |\n",
    "| 174        | 70        | 64        | 2019-06-18 |\n",
    "| 139        | 29        | 88        | 2019-06-08 |\n",
    "| 107        | 90        | 13        | 2019-07-08 |\n",
    "| 6          | 73        | 29        | 2019-06-09 |\n",
    "| 30         | 65        | 45        | 2019-06-23 |\n",
    "| 27         | 40        | 84        | 2019-07-03 |\n",
    "| 78         | 87        | 97        | 2019-07-21 |\n",
    "| 95         | 64        | 73        | 2019-06-27 |\n",
    "| 133        | 40        | 64        | 2019-06-30 |\n",
    "| 146        | 53        | 58        | 2019-07-14 |\n",
    "| 37         | 83        | 48        | 2019-06-23 |\n",
    "| 179        | 64        | 99        | 2019-06-28 |\n",
    "| 45         | 16        | 56        | 2019-07-23 |\n",
    "| 186        | 28        | 66        | 2019-07-30 |\n",
    "| 4          | 34        | 74        | 2019-07-10 |\n",
    "| 49         | 18        | 4         | 2019-07-11 |\n",
    "| 111        | 71        | 99        | 2019-06-17 |\n",
    "| 10         | 78        | 66        | 2019-06-26 |\n",
    "| 183        | 13        | 45        | 2019-06-01 |\n",
    "| 57         | 57        | 2         | 2019-07-20 |\n",
    "| 32         | 93        | 31        | 2019-07-11 |\n",
    "| 133        | 40        | 55        | 2019-06-27 |\n",
    "| 20         | 19        | 33        | 2019-06-03 |\n",
    "| 92         | 74        | 36        | 2019-06-16 |\n",
    "| 10         | 78        | 21        | 2019-07-11 |\n",
    "| 73         | 84        | 43        | 2019-07-28 |\n",
    "| 133        | 40        | 62        | 2019-07-20 |\n",
    "| 152        | 44        | 7         | 2019-07-26 |\n",
    "| 139        | 29        | 86        | 2019-08-01 |\n",
    "| 121        | 5         | 37        | 2019-07-06 |\n",
    "| 109        | 47        | 2         | 2019-07-23 |\n",
    "| 165        | 42        | 39        | 2019-06-25 |\n",
    "| 66         | 32        | 30        | 2019-07-18 |\n",
    "| 130        | 2         | 24        | 2019-07-09 |\n",
    "| 134        | 20        | 73        | 2019-07-07 |\n",
    "| 91         | 55        | 64        | 2019-07-11 |\n",
    "| 123        | 50        | 28        | 2019-07-12 |\n",
    "| 145        | 88        | 49        | 2019-06-23 |\n",
    "| 13         | 93        | 33        | 2019-07-24 |\n",
    "| 29         | 8         | 30        | 2019-07-27 |\n",
    "| 11         | 53        | 1         | 2019-07-23 |\n",
    "| 33         | 98        | 10        | 2019-07-27 |\n",
    "| 23         | 18        | 39        | 2019-07-13 |\n",
    "| 23         | 18        | 27        | 2019-07-23 |\n",
    "| 144        | 66        | 71        | 2019-07-11 |\n",
    "| 108        | 19        | 11        | 2019-06-09 |\n",
    "| 41         | 23        | 66        | 2019-06-05 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be642951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>viewer_id</th>\n",
       "      <th>view_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>17</td>\n",
       "      <td>62</td>\n",
       "      <td>2019-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>2019-06-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>2019-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165</td>\n",
       "      <td>42</td>\n",
       "      <td>74</td>\n",
       "      <td>2019-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>95</td>\n",
       "      <td>91</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>2019-07-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>2019-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>144</td>\n",
       "      <td>66</td>\n",
       "      <td>71</td>\n",
       "      <td>2019-07-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>108</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2019-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>41</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>2019-06-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id  author_id  viewer_id   view_date\n",
       "0           126         17         62  2019-07-02\n",
       "1           149         42         22  2019-06-23\n",
       "2           138         39         33  2019-07-26\n",
       "3           165         42         74  2019-07-05\n",
       "4            48         95         91  2019-06-28\n",
       "..          ...        ...        ...         ...\n",
       "495          23         18         39  2019-07-13\n",
       "496          23         18         27  2019-07-23\n",
       "497         144         66         71  2019-07-11\n",
       "498         108         19         11  2019-06-09\n",
       "499          41         23         66  2019-06-05\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views=pd.read_table('views.csv', sep=' *\\|* ', engine='python')\n",
    "views.drop(columns=['Unnamed: 0','|'], axis=1, inplace=True)\n",
    "views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e730049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def article_views(views: pd.DataFrame) -> pd.DataFrame:\n",
    "    views.drop_duplicates(inplace=True)\n",
    "    selected_rows = views[views['author_id'] == views['viewer_id']]\n",
    "    selected_rows_df = selected_rows[['author_id']].rename(columns={'author_id': 'id'})\n",
    "\n",
    "    # Check if selected_rows_df is empty before sorting\n",
    "    if not selected_rows_df.empty:\n",
    "        selected_rows_df.sort_values(by='id', inplace=True)\n",
    "        selected_rows_df.drop_duplicates(subset='id', keep='first', inplace=True)\n",
    "    # Reset the index before returning\n",
    "    selected_rows_df.reset_index(drop=True, inplace=True)\n",
    "    return selected_rows_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46c8a551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id\n",
       "0   5\n",
       "1  17\n",
       "2  28\n",
       "3  40\n",
       "4  60\n",
       "5  71"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=article_views(views)\n",
    "result_ids = views['article_id'].iloc[result.index]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6753fa6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    126\n",
       "1    149\n",
       "2    138\n",
       "3    165\n",
       "4     48\n",
       "5    151\n",
       "Name: article_id, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0aa10a",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2bcba",
   "metadata": {},
   "source": [
    "+----------------+---------+\n",
    "| Column Name    | Type    |\n",
    "+----------------+---------+\n",
    "| tweet_id       | int     |\n",
    "| content        | varchar |\n",
    "+----------------+---------+\n",
    "tweet_id is the primary key (column with unique values) for this table.\n",
    "This table contains all the tweets in a social media app.\n",
    " \n",
    "\n",
    "Write a solution to find the IDs of the invalid tweets. The tweet is invalid if the number of characters used in the content of the tweet is strictly greater than 15.\n",
    "\n",
    "Return the result table in any order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbc70209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tweets.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile tweets.csv\n",
    "\n",
    "| tweet_id | content                          |\n",
    "\n",
    "| 1        | Vote for Biden                   |\n",
    "| 2        | Let us make America great again! |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf4bb644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Vote for Biden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Let us make America great again!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                           content\n",
       "0         1                    Vote for Biden\n",
       "1         2  Let us make America great again!"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets=pd.read_table('tweets.csv', sep=r'\\s*\\|\\s*', engine='python',quoting=3)\n",
    "tweets.drop(columns=['Unnamed: 0','Unnamed: 3'],axis=1, inplace=True)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e5f9a",
   "metadata": {},
   "source": [
    "In this code, the quoting parameter is set to 3, which is csv.QUOTE_NONE. This setting treats quotes as regular characters and should prevent the issue of quotes being ignored when a multi-character delimiter is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2592e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def invalid_tweets(tweets: pd.DataFrame) -> pd.DataFrame:\n",
    "    invalid_tweets_df = []\n",
    "    for index, row in tweets.iterrows():\n",
    "        if len(row['content']) > 15:\n",
    "            invalid_tweets_df.append(row['tweet_id'])\n",
    "\n",
    "    return pd.DataFrame({'tweet_id': invalid_tweets_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e092112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id\n",
       "0         2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_tweets(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b37f80",
   "metadata": {},
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733611fe",
   "metadata": {},
   "source": [
    "+-------------+---------+\n",
    "| Column Name | Type    |\n",
    "+-------------+---------+\n",
    "| employee_id | int     |\n",
    "| name        | varchar |\n",
    "| salary      | int     |\n",
    "+-------------+---------+\n",
    "employee_id is the primary key (column with unique values) for this table.\n",
    "Each row of this table indicates the employee ID, employee name, and salary.\n",
    " \n",
    "\n",
    "Write a solution to calculate the bonus of each employee. The bonus of an employee is 100% of their salary if the ID of the employee is an odd number and the employee's name does not start with the character 'M'. The bonus of an employee is 0 otherwise.\n",
    "\n",
    "Return the result table ordered by employee_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2463c381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing employees.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile employees.csv\n",
    "\n",
    "| employee_id | name    | salary |\n",
    "\n",
    "| 2           | Meir    | 3000   |\n",
    "| 3           | Michael | 3800   |\n",
    "| 7           | Addilyn | 7400   |\n",
    "| 8           | Juan    | 6100   |\n",
    "| 9           | Kannon  | 7700   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fa709f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Meir</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Michael</td>\n",
       "      <td>3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Addilyn</td>\n",
       "      <td>7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Juan</td>\n",
       "      <td>6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Kannon</td>\n",
       "      <td>7700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id     name  salary\n",
       "0            2     Meir    3000\n",
       "1            3  Michael    3800\n",
       "2            7  Addilyn    7400\n",
       "3            8     Juan    6100\n",
       "4            9   Kannon    7700"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees=pd.read_table('employees.csv', sep=' *\\|* ', engine='python')\n",
    "employees.drop(columns=['Unnamed: 0','|'],axis=1, inplace=True)\n",
    "employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "506e4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_special_bonus(employees: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    for index, row in employees.iterrows():\n",
    "        if row['employee_id'] %2 ==0 or row['name'].startswith('M'):\n",
    "            employees.at[index, 'bonus'] = 0\n",
    "        else:\n",
    "            employees.at[index, 'bonus'] = row['salary']\n",
    "    employees_result = employees[['employee_id', 'bonus']]\n",
    "    return employees_result.sort_values('employee_id',ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a3447237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>7400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>7700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id   bonus\n",
       "0            2     0.0\n",
       "1            3     0.0\n",
       "2            7  7400.0\n",
       "3            8     0.0\n",
       "4            9  7700.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_special_bonus(employees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ba9240",
   "metadata": {},
   "source": [
    "# problem 7 Fix Names in a Table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc554de",
   "metadata": {},
   "source": [
    "+----------------+---------+\n",
    "| Column Name    | Type    |\n",
    "+----------------+---------+\n",
    "| user_id        | int     |\n",
    "| name           | varchar |\n",
    "+----------------+---------+\n",
    "user_id is the primary key (column with unique values) for this table.\n",
    "This table contains the ID and the name of the user. The name consists of only lowercase and uppercase characters.\n",
    " \n",
    "\n",
    "Write a solution to fix the names so that only the first character is uppercase and the rest are lowercase.\n",
    "\n",
    "Return the result table ordered by user_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "956ce2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing users.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile users.csv\n",
    "| user_id | name  |\n",
    "\n",
    "| 1       | aLice |\n",
    "| 2       | bOB   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e6bf595e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>aLice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>bOB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   name\n",
       "0        1  aLice\n",
       "1        2    bOB"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users=pd.read_table('users.csv', sep=' *\\|* ', engine='python')\n",
    "users.drop(columns=['Unnamed: 0','|'], axis=1, inplace=True)\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc4c4083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fix_names(users: pd.DataFrame) -> pd.DataFrame:\n",
    "    users['name']=users['name'].str.title()\n",
    "    return users.sort_values('user_id', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0f494a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   name\n",
       "0        1  Alice\n",
       "1        2    Bob"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_names(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa361e0",
   "metadata": {},
   "source": [
    "# Problem 8 Find Users With Valid E-Mails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19860ef",
   "metadata": {},
   "source": [
    " +---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| user_id       | int     |\n",
    "| name          | varchar |\n",
    "| mail          | varchar |\n",
    "+---------------+---------+\n",
    "user_id is the primary key (column with unique values) for this table.\n",
    "This table contains information of the users signed up in a website. Some e-mails are invalid.\n",
    " \n",
    "\n",
    "Write a solution to find the users who have valid emails.\n",
    "\n",
    "A valid e-mail has a prefix name and a domain where:\n",
    "\n",
    "The prefix name is a string that may contain letters (upper or lower case), digits, underscore '_', period '.', and/or dash '-'. The prefix name must start with a letter.\n",
    "The domain is '@leetcode.com'.\n",
    "Return the result table in any order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "91f9bc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting users.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile users.csv\n",
    "\n",
    "| user_id | name      | mail                    |\n",
    "\n",
    "| 1       | Winston   | winston@leetcode.com    |\n",
    "| 2       | Jonathan  | jonathanisgreat         |\n",
    "| 3       | Annabelle | bella-@leetcode.com     |\n",
    "| 4       | Sally     | sally.come@leetcode.com |\n",
    "| 5       | Marwan    | quarz#2020@leetcode.com \n",
    "| 6       | David     | david69@gmail.com       |\n",
    "| 7       | Shapiro   | .shapo@leetcode.com     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3fd7c4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Winston</td>\n",
       "      <td>winston@leetcode.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>jonathanisgreat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Annabelle</td>\n",
       "      <td>bella-@leetcode.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sally</td>\n",
       "      <td>sally.come@leetcode.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Marwan</td>\n",
       "      <td>quarz#2020@leetcode.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>David</td>\n",
       "      <td>david69@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Shapiro</td>\n",
       "      <td>.shapo@leetcode.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       name                     mail\n",
       "0        1    Winston     winston@leetcode.com\n",
       "1        2   Jonathan          jonathanisgreat\n",
       "2        3  Annabelle      bella-@leetcode.com\n",
       "3        4      Sally  sally.come@leetcode.com\n",
       "4        5     Marwan  quarz#2020@leetcode.com\n",
       "5        6      David        david69@gmail.com\n",
       "6        7    Shapiro      .shapo@leetcode.com"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users=pd.read_table('users.csv', sep=' *\\|* ', engine='python')\n",
    "users.drop(columns=['|','Unnamed: 0'], axis=1, inplace=True)\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002dbf2a",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "def valid_emails(users: pd.DataFrame) -> pd.DataFrame:\n",
    "    valid_users=users.copy()\n",
    "    for index, row in valid_users.iterrows():\n",
    "        email=row['mail']\n",
    "        if not re.match(r'^[A-Za-z][A-Za-z0-9_.-]*@leetcode\\.com$', email):\n",
    "            valid_users.drop(index, axis=0, inplace=True)\n",
    "    return valid_users\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2624d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "def valid_emails(users: pd.DataFrame) -> pd.DataFrame:\n",
    "    valid_mail=users[users['mail'].str.match(r'^[A-Za-z][A-Za-z0-9_.-]*@leetcode\\.com$')]\n",
    "    return valid_mail        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "887dc3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Winston</td>\n",
       "      <td>winston@leetcode.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Annabelle</td>\n",
       "      <td>bella-@leetcode.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sally</td>\n",
       "      <td>sally.come@leetcode.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       name                     mail\n",
       "0        1    Winston     winston@leetcode.com\n",
       "2        3  Annabelle      bella-@leetcode.com\n",
       "3        4      Sally  sally.come@leetcode.com"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_emails(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccdc283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18d75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
